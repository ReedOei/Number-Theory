\documentclass{article}

\usepackage{minted}
\usepackage{amsmath}
\usepackage{amssymb}

\newcommand{\inline}[1]{\mintinline{idris}{#1}}

\begin{document}

\section{Introduction}
Hello/welcome and such.

This book assumes you have basic mathematical fluency in something like a discrete math course.
You'll probably be fine either way, as long as you've encountered some basics like functions and the concept of natural numbers before.
Previous programming experience probably won't help you, unless it's in Haskell or another functional language (if you don't know what that means, you're still good, just read on and pay very close attention).

I encourage you to type everything in for yourself to see how it works.

\section{Introduction to Idris}

Idris is a purely functional programming language.

Purely functional means two things: that all functions are pure, and that programs in Idris are based around the composition of functions (functional programming doesn't really have a widely accepted definition).
Pure functions are functions that return the same output given the same input.
For example, using $f(x) = x + 5$, $f(3)$ is always 8, and it will never sometimes end up being 16 or 4, or any other number.
Another important facet of Idris is that functions act just like normal values.
For example, I can define a function $g(f, x) = f(x)$.
This function takes two arguments, a function $f$ and a value $x$, and returns $f(x)$.
For example, with $f(x) = x + 5$, $g(f, 8) = f(8) = 13$.
However, if I use the sine function, I get: $g(sin, \pi) = sin(\pi) = 0$.

We will be using Idris to write proofs, and it will check our proofs for us, so we can be sure that we did it right.
However, in addition to being able to check proofs, Idris is also a general purpose programming language, so you could reasonably program just about anything in it.

\subsection{Defining Functions}
As Idris is a functional language, defining functions is the most important part of Idris.
On a very basic level, you can think of functions in Idris as being just like mathematical functions: mappings from one set to another.

For example, if I want to write a function $p$ from a set $A$ to another set $B$, I would write:

$$p : A \rightarrow B$$

In Idris, if I want to write a function \inline{p} from a type \inline{a} to another type \inline{b}, I would type:

\begin{minted}{idris}
p : a -> b
\end{minted}

If we were going to actually define this function in Idris, we would start by writing:

\begin{minted}{idris}
p : a -> b
p a = ?something
\end{minted}

where \inline{a} in line 2 is the value of type \inline{a} that we passed to the function.
Here \inline{?something} is called a ``hole.''
Basically, it's a placeholder for some definition that we will eventually provide.
Idris basically just ignores holes altogether, but it will tell you the type of the hole if you ask.
To do this, simply type at the Idris REPL:

\begin{minted}{idris}
> something
\end{minted}

And Idris will respond with the type of the value that needs to go in place of \inline{?something} to complete the definition.

For a more concrete example:

\begin{minted}{idris}
p : Integer -> Integer
p x = x + 2
\end{minted}

This is a function from the integers to the integers, that takes any integer, called $x$, and returns another integer, namely, $x + 2$.
In math, we would write this as:
\[
    p : \mathbb{Z} \rightarrow \mathbb{Z}
\]

\[
    p(x) = x + 2
\]

If we want multiple arguments to our functions (e.g., a function that calculates the distance to a point from the origin), then we would write:

\begin{minted}{idris}
distance : Double -> Double -> Double
distance x y = sqrt (pow x 2 + pow y 2)
\end{minted}

This is the same as writing:

\[
    \mathrm{distance}(x, y) = \sqrt{x^2 + y^2}
\]

\paragraph{Exercises}

\begin{enumerate}
    \item Write a function in Idris that calculates $f(x) = x^2$
    \item Write a function in Idris that calculates $f(x,y) = g(x) + g(y)$ where $g(x) = (x + 2)^2$
\end{enumerate}

\subsection{Types}
Types are very important.
They make writing, maintaining, and reading programs easier.
This is a fairly straight forward and obvious idea: taking the length of a list makes sense, but what is the the length of an \inline{Integer}?
Now, you could check for this at runtime like you would in Python, but, ultimately, that could lead to errors that are easily prevented before you even run the program.

In Idris, we write the sentence ``\inline{x} is of type \inline{a}`` as \inline{x : a}.

For example, we have:

\begin{minted}{idris}
1 : Integer
1.0 : Double
"Hello" : String
\end{minted}

However, in Idris, types are even more important than in many languages.
Idris has \textit{dependent} types, which we'll talking about in depth later (and are what makes this entire book possible).

\subsubsection{Built-in Types}
Idris, like many programming languages has a number of built-in types, meaning that they come with Idris without having to write any code or install any other modules.
The most important of these are:

\begin{itemize}
    \item[\inline{Nat}] Natural numbers, starting from 0 and going on forever.
    \item[\inline{Integer}] The same as a normal integer in math.
        Unlike many languages, \inline{Integer} in Idris is arbitrary precision, meaning that there is no limit to its size.
    \item[\inline{Double}] Used to hold non-integer numbers like 1.5 or 0.31.
    \item[\inline{Char}] A single character, like 'a' or '.'.
    \item[\inline{String}] A string of characters, like "hello" or "Idris".
\end{itemize}

\subsubsection{Tuples}
Often, having multiple values is easy.
One of the ways to pass multiple values to, or return multiple values from, a function in Idris is via \textit{tuples}.
An example of a tuple is a pair, $(x, y)$, but they can be any size, (e.g., $(x, y, z, w, a, b, c)$).
We write the type of a tuple in Idris very simply, for example, a pair of two integers is: \inline{(1, 2) : (Integer, Integer)}.

Tuples cannot change size, which makes them good for representing data that we know always comes in pairs (e.g., coordinates), but not for representing data that can grow or shrink in length.
For that, we turn to lists.

\subsubsection{Lists}

\subsubsection{Function Types}
\paragraph{Currying}

\subsection{Recursion}

\subsection{Pattern Matching}

\subsection{Defining Custom Types}

\subsection{Dependent Types}

\subsection{Proving Things in a Programming Language?}
\subsubsection{Basic Propositions}

Recall that, if I have a function:

\begin{minted}{idris}
p : a -> b
\end{minted}

We can think about this as a proposition, that says, given \inline{a}, I can prove \inline{b}.
We can extend this to a couple other common logical operators, such as $\wedge$, also called ``and'', and $\vee$, also called ``or''.
How might we represent $\wedge$?

With a pair, (a, b). Remember, the idea here is that, if I have a value with this type, then I have proven that it is true. So if I have (a, b), then I must have both an a and a b, or, equivalently, proofs of both. Another way to express this is by using an implication:

\begin{minted}{idris}
a -> b -> c
\end{minted}

This says that if I have a proof of \inline{a}, if I have a proof \inline{b}, then I can create a proof of \inline{c}.
Simple manipulation of the logical operators will show this is the same as knowing both \inline{a} and \inline{b}. % TODO Maybe actually include this.
Let’s use this briefly to show how it works just like the normal ``and'' operator.

Imagine we are trying to prove that, given $A$ and $B$, I can prove $A$.
Obviously this is true, since we've assumed $A$.

This is what the type would be in Idris:
\begin{minted}{idris}
a -> b -> a
\end{minted}

How do we write a function with this type?

\begin{minted}{idris}
f : a -> b -> a
f a b = a
\end{minted}

The first argument is an \inline{a}, and we need to prove \inline{a} (remember, this is equivalent to producing a value of the type \inline{a}).
So, let's just immediately return the first argument.

Finally, let’s show how to represent ``or'' in Idris.
We can do this via the following:

\begin{minted}{idris}
data Either a b = Left a | Right b
\end{minted}

This will take a bit more explanation, but it's not super complicated.
Basically, we have a type called \inline{Either}, and we have two ways to create values of this type.
Just like you can create a value of the type \inline{Bool} by writing either \inline{True} or \inline{False}, you can create a value of the type \inline{Either} with either a value of the \inline{Left} type, \inline{a}, or the \inline{Right} type, \inline{b}.
Note that we do not need both, as that is the key.
So if we can create a value of the type \inline{Either a b} with just an \inline{a} or just a \inline{b}, this successfully represents the standard ``or'' operator.

\paragraph{Exercises}

\subsubsection{Predicates}
Now, we’ll extend this idea past just simple boolean propositions, and include numbers and more complicated predicates.
Basically, now we will take things like numbers, rather than just values of any type, and show that certain conditions are true.

For example:

\begin{minted}{idris}
(a, b) : Nat -> LTE a b -> LTE 0 (b - a)
\end{minted}

This is a more complicated proposition, but it is hopefully not incomprehensible.
This says, “given two natural numbers $a$ and $b$, and a proof that $a \leq b$, I can show that $b - a$ is at least $0$.”
Equivalently:

\[
    \forall a, b \in \mathbb{N}, a \leq b, b - a \geq 0
\]

There is one more important feature that our functions must have to be true proofs: totality.
This means that the function is defined for every possible input.
For mathematical functions, this is generally included as part of the definition of a function, but often programmers will write functions that are not total.
This is no good, because if you don't include that case, then you've only proved the proposition for the cases you did define.
To make sure that all our functions are total, we can write total before their definition, and Idris will let us know if we missed any cases.

\begin{minted}{idris}
-- This will be fine
total
f : Integer -> Integer
f x = x + 2

-- This will be an error (note that we are missing the case for an empty list)
total
g : List a -> a
g (x :: xs) = x
\end{minted}

If you want to read more about this sort of thing, see the Curry--Howard correspondence (and related topics).

\section{Natural Numbers ($\mathbb{N}$)}
\subsection{Definition}
Now, starting on the actual proof.
So, first, let's state the axioms we'll be using, which are just the basic Peano axioms, first using ``normal'' math, then in Idris.
First, the definition of the natural numbers, which is two of the normal Peano axioms:
A natural number is either 0, or the successor (i.e., one more than) of another natural number.

Examples:
\begin{itemize}
    \item 0
    \item 1 (which is one more than 0)
    \item 2 (which is one more than 1)
    \item 5 (which is one more than 4, which is one more than 3, which is one more than 2)
\end{itemize}

Now, in Idris, we define the natural numbers as:
\begin{minted}{idris}
data Nat : Type where
    Z : Nat
    S : Nat -> Nat
\end{minted}

This is the same thing, saying that a value of the type \inline{Nat} is either \inline{Z} (i.e. 0) or \inline{S n} where \inline{n} is another natural number.

\subsection{Peano Axioms}
We will be relying on the Peano axioms to prove all of our propositions in this book.
Two of the Peano axioms establish the above definition of the natural numbers.
They are expressed below in both ``normal'' math and Idris.

\begin{enumerate}
    \item For any natural number $x$, $x = x$.
        This is hopefully obviously true, and needs no explanation.
        In Idris, however, the definition of equality can seem a little confusing.
        Here it is:

        \begin{minted}{idris}
        data (=) : (x : A) -> (y : A) -> Type where
            Refl : x = x
        \end{minted}

        The strange part is the \inline{Refl} takes no arguments.
        That is not quite true, as it takes \textit{implicit} arguments, as described before.
        The this definition gives us the same thing as the Peano axioms however, as it only takes one argument, and therefore is definitionally true.
        What it means in practice for two things to be equal in Idris is that they are constructed in the same way, i.e., that they use the constructors \inline{S} and \inline{Z} the same number of times and in the same way (e.g. \inline{S (S (S Z))} is the same as \inline{S (S (S Z))}, because both are constructed from three consecutive calls to \inline{S} on \inline{Z}).

    \item If $x = y$, then $y = x$.
        Again, no surprises here.
        In Idris we write this using the function \inline{sym : (x = y) -> y = x}.
        Here we see again the constructive nature of proving things in Idris, \inline{sym} takes a \textit{proof} that $x = y$ and then we get a proof that $y = x$.

    \item If $x = y$, and $y = z$, then $x = z$.
        Again, there is a simple function in Idris that expresses this fact: \inline{trans : (x = y) -> (y = z) -> x = z}.

    \item $m = n$ if and only if $S(m) = S(n)$.
        Here we express each direction of the implication in two ways in Idris.
        Firstly, if $m = n$, then $S(m) = S(n)$, is written with \inline{eqSucc : (a : Nat) -> (b : Nat) -> (a = b) -> S a = S b}.
        Here we see the first use of the dependent types so far.
        \inline{eqSucc} takes two natural numbers, $a$ and $b$, and a proof that they are equal, and then gives us a proof back that their successors are equal.
        We need the dependent types because we need to refer to the values of $a$ and $b$ later in the type to make sure we get a proof of the right thing.

        Now, the other direction, if $S(n) = S(m)$, then $n = m$.
        This is written using the similar function \inline{succInjective : (a : Nat) -> (b : Nat) -> (S a = S b) -> a = b}
        We can see this is the same function, except with the last two parts (\inline{S a = S b} and \inline{a = b}) flipped.
        Notice this is true for all injective functions, which is why the name is \inline{succInjective}.

    \item For every natural number $n$, $S(n) \neq 0$.
        This proof will be a little stranger, as it is a negative proof.
        However, as discussed before, the key to writing a proof of a negative is proving that, if the proposition were true, then we would get \inline{Void}, from which we can prove anything.
        To do this in Idris, we use the following function: \inline{SIsNotZ : (S n = Z) -> Void}.
        Again, \inline{n} here is an implicit parameter.
\end{enumerate}

\subsection{Addition and Multiplication}
Now, we must define addition and multiplication, because it's such a basic notion that there is basically nothing interesting we can say without it.
Addition is defined as follows:

\begin{itemize}
    \item[] $0 + m = m$
    \item[] $S(n) + m = S(n + m)$
\end{itemize}

Notice this definition is recursive.
In Idris, the definition is very similar (note that \inline{plus} is equivalent to \inline{+}):

\begin{minted}{idris}
total
plus : (n, m) : Nat -> Nat
plus Z m = m
plus (S n) m = S (plus n m)
\end{minted}

Here is the definition of multiplication, which is quite similar to the definition of addition, and is simply repeated addition:

\begin{itemize}
    \item[] 0 * n = 0
    \item[] S(n) * m = m + (n * m)
\end{itemize}

And in Idris (once again noting that \inline{mult} is equivalent to \inline{*}):

\begin{minted}{idris}
total
mult : (n, m : Nat) -> Nat
mult Z m = Z
mult (S n) m = plus m (mult n m)
\end{minted}

\subsection{Examples}

\subsection{Exercises}

\section{Basic Proofs}
\subsection{Additive Identity}
One of the most basic things we can prove is that addition zero does not affect a number, specifically, the following propositions:

\begin{minted}{idris}
zIsIdLeft : (n : Nat) -> n = plus 0 n
zIsIdRight : (n : Nat) -> n = plus n 0
\end{minted}

Notice that we have to prove it twice, because they are technically different propositions.
Let's tackle the first one first (naturally), because that's the easier one.
First, let's take a look at our definition of addition, specifically, the first case:

\begin{minted}{idris}
plus Z m = m
\end{minted}

This means that whenever we have \inline{plus Z m}, we know we can simplify it to \inline{m} by definition.
Notice how this is exactly what we wrote in our type, except the equality is flipped.
If it weren't, we could simply write:

\begin{minted}{idris}
zIsIdLeft : (n : Nat) -> n = plus 0 n
zIsIdLeft n = Refl
\end{minted}

Luckily we have a function that flips the equality, called \inline{sym}, so we can write this instead:

\begin{minted}{idris}
zIsIdLeft : (n : Nat) -> n = plus 0 n
zIsIdLeft n = sym Refl
\end{minted}

The next proposition, \inline{zIsIdRight} is slightly more complicated, so we'll split it into cases.
The two possible cases for any natural number are either \inline{Z} or \inline{S n}, so:

\begin{minted}{idris}
zIsIdRight : (n : Nat) -> n = plus n 0
zIsIdRight Z = ?nIsZero
zIsIdRight (S n) = ?nIsSucc
\end{minted}

Notice in the first case we can use the definition of addition to simplify again, so we simply have \inline{zIsIdRight Z = Refl}.
But what do we do in the other case?
Here is our first recursive proof.

We need a proof that the proposition is true for \inline{S n}.
The only way we know to get a proof of this is from the \inline{zIsIdRight} function itself, so let's use that.
But of course, that only gives us a proof that \inline{n = plus n 0}, while we need that \inline{S n = plus (S n) 0}.
Luckily we know that \inline{a = b -> S a = S b}, and we know that \inline{plus (S n) 0 = S (plus n 0)} by the definition of addition.
Combining these two via \inline{eqSucc}, we can prove this proposition in its entirety as follows:

\begin{minted}{idris}
zIsIdRight : (n : Nat) -> n = plus n 0
zIsIdRight Z = Refl
zIsIdRight (S n) = eqSucc n (plus n 0) (zIsIdRight n)
\end{minted}

This is a very common tactic for proving things, so it's good to get used to it now.

Proving it twice was pretty annoying right?
Especially because we know that addition commutes (i.e., $m + n = n + m$), so there's really no reason to.
Let's prove that addition is commutative next, so we no longer have to do that.

\subsection{Commutivity}
Let's being by stating our proposition, that addition commutes, in Idris:

\begin{minted}{idris}
additionCommutes : (a, b : Nat) -> a + b = b + a
\end{minted}

This says that, if I have two natural numbers, $a$ and $b$, then I know that $a + b = b + a$.
Now, let’s try and write a function like this.

\begin{minted}{idris}
additionCommutes a b = ?something
\end{minted}

The easiest way to do this is, as usual, to break the problem up into smaller parts, specifically, into cases. So let’s do that now:

\begin{minted}{idris}
additionCommutes Z Z = ?something
additionCommutes Z (S k) = ?something2
additionCommutes (S k) Z = ?something3
additionCommutes (S k) (S j) = ?something4
\end{minted}

Here are our four cases.
The first case is when both \inline{a} and \inline{b} are zero.
That case is quite simple, because our definition of addition will immediately evaluate both to be zero, so we can simply use the reflexive property here.
So that case becomes:

\begin{minted}{idris}
additionCommutes Z Z = Refl
\end{minted}

Now let’s look at the next two cases. In the first of these, we want to show the following:
\begin{minted}{idris}
Z + (S k) = (S k) + Z
\end{minted}

However, by our definition of addition, the left hand side really simplifies to just \inline{S k}, so we now need to show:

\begin{minted}{idris}
S k = S k + Z
\end{minted}

But wait!
This is exactly what we'd get from using \inline{zIsIdRight : (n : Nat) -> n = plus n 0}, so let's just do that.

So that takes care of the case of:

\begin{minted}{idris}
additionCommutes Z (S k) = zIsIdRight (S k)
\end{minted}

The next case, \inline{additionCommutes (S k) Z} is almost identical, except here we’re trying to show that \inline{S k + Z = Z + S k}.
Here, the right hand side, rather than the left, immediately simplifies.
So this is exactly the same as what we just proved, just flipped (i.e., it is \inline{S k + Z = S k}), which means we need to use \inline{sym}.
So we can complete the next case with:

\begin{minted}{idris}
additionCommutes (S k) Z = sym (zIsIdRight (S k))
\end{minted}

Now there is only one case left, which is:

\begin{minted}{idris}
additionCommutes (S k) (S j) = ?something
\end{minted}

We will use the definition recursively, so that we will eventually reach one of the other cases that we have already proven the claim for.
Specifically, we want to use \inline{additionCommutes k j} in our proof.
So with that call, we have a proof of \inline{k + j = j + k}, but we want to prove \inline{S (k + S j) = S (j + S k)}, which is unfortunately not just a simple application of \inline{eqSucc}.
So how can we do this?

The first step is to realize that, if we know that \inline{k + S j = j + S k}, we can easily use \inline{eqSucc} to prove the final result.
So let’s focus on proving that smaller claim.
By our definition of addition, we know that \inline{k + S j = S (k + j)}.
We can formalize this in Idris as follows:

\begin{minted}{idris}
addSIsS : (k, j : Nat) -> k + S j = S (k + j)
addSIsS Z j = Refl
addSISS (S k) j = eqSucc (k + S j) (S (k + j)) (addSIsS k j)
\end{minted}

As usual we can trivially show this is true when \inline{k = Z}, simply by the definition of addition.
Then, we use a recursive call to prove that the statement is true for the predecessor (the opposite of the successor), that is, \inline{k + S j = S (k + j)}.
Finally we use our familiar \inline{eqSucc} to obtain our desired final result.

Now that we have this, let’s take a step back, and look at what we can show:

We can show that, given \inline{S k} and \inline{S j}, that \inline{k + j = j + k}, via a recursive call to \inline{additionCommutes}, and therefore that \inline{S (k + j) = S (j + k)}.
We can show that \inline{k + S j = S (k + j)} via \inline{addSIsS}, and therefore also \inline{j + S k = S (j + k)}.
And let’s remind ourselves of our current goal for our lemma:

\begin{minted}{idris}
(k, j : Nat) -> k + S j = j + S k
\end{minted}

So, if you look closely, you will see we can do this easily as follows (note that each equality is something we can prove, as noted above):

\begin{minted}{idris}
k + S j = S (k + j) -- Via addSIsS k j
S (k + j) = S (j + k) -- Via eqSucc and additionCommutes
S (j + k) = j + S k -- Via addSIsS j k
\end{minted}

The last of these we obtain by using the symmetric property on \inline{addSIsS}.
So how do we link these together?
By using the transitive property, which is one of the Peano axioms, written in Idris as:

\begin{minted}{idris}
trans : a = b -> b = c -> a = c
\end{minted}

By applying this twice, we can get our desired result (although unfortunately it looks a little messy):

\begin{minted}{idris}
lemma : (k, j : Nat) -> k + S j = j + S k
lemma k j = trans (trans (addSIsS k j)
                         (eqSucc (k + j) (j + k) (additionCommutes k j)))
                  (sym (addSIsS j k))
\end{minted}

Now, we can show the following easily, via a single call to \inline{eqSucc}.

\begin{minted}{idris}
(k, j : Nat) -> S (k + S j) = S (j + S k)
\end{minted}

Now, looking back at our original function, \inline{additionCommutes}, we can see that that’s exactly what we needed to prove, so let’s just shove this in there, and we’re done!

Final code (the mutual block is required to have mutual recursion, i.e., \inline{lemma}, which calls \inline{additionCommutes}, and \inline{additionCommutes}, which calls \inline{lemma}):

\begin{minted}{idris}
addSIsS: (a, b : Nat) -> a + S b = S (a + b)
addSIsS Z b = Refl
addSIsS (S k) b = eqSucc (k + S b) (S (k + b)) (addSIsS k b)

mutual
    lemma : (k, j : Nat) -> k + S j = j + S k
    lemma k j = trans (trans (addSIsS k j)
                             (eqSucc (k + j) (j + k) (additionCommutes k j)))
                      (sym (addSIsS j k))

    additionCommutesLemma : (k, j : Nat) -> S (plus k (S j)) = S (plus j (S k))
    additionCommutesLemma k j = eqSucc (k + S j) (j + S k) (lemma k j)

    additionCommutes : (a, b : Nat) -> a + b = b + a
    additionCommutes Z Z = Refl
    additionCommutes Z (S k) = zIsIdRight (S k)
    additionCommutes (S k) Z = sym (zIsIdRight (S k))
    additionCommutes (S k) (S j) = additionCommutesLemma k j
\end{minted}

\subsection{Associativity}
Proving \inline{addSIsS : (a, b : Nat) -> a + S b = S (a + b)} was pretty annoying, because it's another fact that we intuitively ``know''.
So let's generalize it, then prove it, so we don't have to do with anything like it again.
This is better known as the associative property, i.e., $a + (b + c) = (a + b) + c$.
In Idris, we would write (hopefully you could guess at the definition):

\begin{minted}{idris}
additionAssociates : (a, b, c : Nat) -> a + (b + c) -> (a + b) + c
additionAssociates Z b c = ?aIsZ
additionAssociates (S a) b c = ?aIsS
\end{minted}

We could split this into 8 cases, but it turns out that's unnecessary and a \textbf{lot} more work.
In the first case, we can use the definition of addition to simplify it immediately.
Notice for the second case, we are looking to prove \inline{S a + (b + c) -> (S a + b) + c}.
Applying the definition of addition one to the left hand side gives \inline{S (a + (b + c))} and twice to the right hand side give \inline{S ((a + b) + c)}.
This is exactly a proof that addition associates, just for the predecessor of \inline{a}!
This means it's a simple case of using \inline{eqSucc} and a recursive call.
The final proof looks like this:

\begin{minted}{idris}
additionAssociates : (a, b, c : Nat) -> a + (b + c) -> (a + b) + c
additionAssociates Z b c = Refl
additionAssociates (S a) b c = let recursive = additionAssociates a b c in
                                   eqSucc (a + (b + c)) ((a + b) + c) recursive
\end{minted}

We could re-express \inline{addSIsS} using \inline{additionAssociates}, but it's actually much longer and more confusing than our definition.

\subsection{Canceling and Adding}
In this section, we'll prove that, if $a + c = b + c$, then $a = b$, and if $c + a = c + b$, then $a = b$.

\subsubsection{Addition Cancels Left}

\subsubsection{Addition Cancels Right}

\subsection{Multiplication}

\paragraph{Exercises}
Try to prove the following theorems.
The proofs will be similar to the proofs above, as they're essentially the same properties, but in reverse.
Start by expressing them as a type in Idris, then enumerating the possible cases, using as few cases as possible (though it isn't a big deal if you have more than necessary).

\begin{enumerate}
    \item If $a + b = c$, then $b + a = c$.
    \item If $a = b$, then $a + c = b + c$.
    \item If $a = b$, then $c + a = c + b$.
    \item Express \inline{addSIsS} using \inline{additionAssociates}.
\end{enumerate}

The answers can be found in the appendix.

\section{Less, Greater}

\section{Divides, GCD, LCM}
\subsection{Divides}

\subsection{GCD}
\subsubsection{In Idris}

\subsection{LCM}
\subsubsection{In Idris}

\section{Prime Numbers}
\subsection{Definition}
\subsubsection{In Idris}

\subsection{There Are Infinitely Many Primes}

\subsection{Fundamental Theorem of Arithmetic}

\section{Ring of Integers Modulo $n$}
\subsection{Definition of Ring}
\subsubsection{In Idris}

\subsection{Definition of Congruence Modulo $n$}

\subsection{Euler's $\varphi$-function}

\subsection{Euler's Theorem}

\subsection{Chinese Remainder Theorem}

\section{}

\section{Appendix}

\subsection{Answers}

\begin{enumerate}
    \item If $a + b = c$, then $b + a = c$.

\begin{minted}{idris}
additionCommutesEq : (a, b, c : Nat) -> a + b = c -> b + a = c
additionCommutesEq a b c prf = trans (additionCommutes b a) prf
\end{minted}

    \item If $a = b$, then $a + c = b + c$.

\begin{minted}{idris}
additionEqLeft : (a, b, c : Nat) -> a = b -> c + a = c + b
additionEqLeft a b Z prf = prf
additionEqLeft a b (S c) prf = eqSucc (c + a) (c + b) (additionEqLeft a b c prf)
\end{minted}

    \item If $a = b$, then $c + a = c + b$.

\begin{minted}{idris}
additionEqRight : (a, b, c : Nat) -> a = b -> a + c = b + c
additionEqRight a b c prf =
    let leftAdd = additionEqLeft a b c prf
        flipCPlusA = additionCommutesEq c a (c + b) leftAdd in
        sym (additionCommutesEq c b (a + c) (sym flipCPlusA))
\end{minted}

    \item Express \inline{addSIsS} using \inline{additionAssociates}.

% TODO Not the nicest...improve?

\begin{minted}{idris}
addSIsS : (a, b : Nat) -> a + S b = S (a + b)
addSIsS a b =
        -- Prove a + (1 + b) = a + (b + 1)
    let addOne = additionEqLeft (1 + b) (b + 1) a (additionCommutes 1 b)
        -- Prove a + (b + 1) = (a + b) + 1
        associate = additionAssociates a b 1
        -- Transform (a + b) + 1 to 1 + (a + b)
        commute = additionCommutes (a + b) 1
        -- Transform 1 + (a + b) = (1 + a) + b
        associateCommute = additionAssociates 1 a b in
        -- a + (1 + b) = a + (b + 1) = (a + b) + 1 = 1 + (a + b) = (1 + a) + b
        -- Then a + (1 + b) = a + S b by def.
        -- Also, (1 + a) + b = S a + b = S (a + b) by def.
        trans (trans (trans addOne associate) commute) associateCommute
\end{minted}

\end{enumerate}

\subsection{Why is any of this valid?}

\subsection{Links}

\end{document}

